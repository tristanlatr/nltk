<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  <head>
    <title>nltk.translate.bleu_score.SmoothingFunction : API documentation</title>

    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
  </head>
  <body>

    <nav class="navbar navbar-default">
      <div class="container">
        <div class="navbar-header navbar-brand">
          <a href="https://github.com/tristanlatr/nltk">Natural Language Toolkit</a>
          <a href="index.html">API Documentation</a>
        </div>
      </div>
    </nav>

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="nltk.html">nltk</a></code>.<code><a href="nltk.translate.html">translate</a></code>.<code><a href="nltk.translate.bleu_score.html">bleu_score</a></code>.<code><a href="nltk.translate.bleu_score.SmoothingFunction.html">SmoothingFunction</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">SmoothingFunction</span>: <a href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L447">(source)</a></code></p>
        <p><a href="classIndex.html#nltk.translate.bleu_score.SmoothingFunction">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div><p class="pre">This is an implementation of the smoothing techniques
for segment-level BLEU scores that was presented in
Boxing Chen and Collin Cherry (2014) A Systematic Comparison of
Smoothing Techniques for Sentence-Level BLEU. In WMT14.
http://acl2014.org/acl2014/W14-33/pdf/W14-3346.pdf</p></div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1865">
  
  <tr class="method">
    
    <td>Method</td>
    <td><code><a href="#__init__">__init__</a></code></td>
    <td><span>This will initialize the parameters required for the various smoothing techniques, the default values are set to the numbers used in the experiments from Chen and Cherry (2014).</span></td>
  </tr><tr class="instancevariable">
    
    <td>Instance Variable</td>
    <td><code><a href="#epsilon">epsilon</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable">
    
    <td>Instance Variable</td>
    <td><code><a href="#alpha">alpha</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable">
    
    <td>Instance Variable</td>
    <td><code><a href="#k">k</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#method0">method0</a></code></td>
    <td><span>No smoothing.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#method1">method1</a></code></td>
    <td><span>Smoothing method 1: Add *epsilon* counts to precision with 0 counts.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#method2">method2</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#method3">method3</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#method4">method4</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#method5">method5</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#method6">method6</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#method7">method7</a></code></td>
    <td><span>Smoothing method 7: Interpolates methods 4 and 5.</span></td>
  </tr>
</table>
        

          
      </div>

      <div id="childList">

        <div class="basemethod">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.__init__">
    
  </a>
  <a name="__init__">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">__init__</span>(self, epsilon=0.1, alpha=5, k=5):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L456">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">This will initialize the parameters required for the various smoothing
techniques, the default values are set to the numbers used in the
experiments from Chen and Cherry (2014).

&gt;&gt;&gt; hypothesis1 = ['It', 'is', 'a', 'guide', 'to', 'action', 'which', 'ensures',
...                 'that', 'the', 'military', 'always', 'obeys', 'the',
...                 'commands', 'of', 'the', 'party']
&gt;&gt;&gt; reference1 = ['It', 'is', 'a', 'guide', 'to', 'action', 'that', 'ensures',
...               'that', 'the', 'military', 'will', 'forever', 'heed',
...               'Party', 'commands']

&gt;&gt;&gt; chencherry = SmoothingFunction()
&gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1)) # doctest: +ELLIPSIS
0.4118...
&gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method0)) # doctest: +ELLIPSIS
0.4118...
&gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method1)) # doctest: +ELLIPSIS
0.4118...
&gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method2)) # doctest: +ELLIPSIS
0.4489...
&gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method3)) # doctest: +ELLIPSIS
0.4118...
&gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method4)) # doctest: +ELLIPSIS
0.4118...
&gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method5)) # doctest: +ELLIPSIS
0.4905...
&gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method6)) # doctest: +ELLIPSIS
0.4135...
&gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method7)) # doctest: +ELLIPSIS
0.4905...

:param epsilon: the epsilon value use in method 1
:type epsilon: float
:param alpha: the alpha value use in method 6
:type alpha: int
:param k: the k value use in method 4
:type k: int</p></div>
  </div>
</div><div class="baseinstancevariable">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.epsilon">
    
  </a>
  <a name="epsilon">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">epsilon</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L496">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.alpha">
    
  </a>
  <a name="alpha">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">alpha</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L497">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.k">
    
  </a>
  <a name="k">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">k</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L498">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.method0">
    
  </a>
  <a name="method0">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">method0</span>(self, p_n, *args, **kwargs):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L500">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">No smoothing.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.method1">
    
  </a>
  <a name="method1">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">method1</span>(self, p_n, *args, **kwargs):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L525">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Smoothing method 1: Add *epsilon* counts to precision with 0 counts.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.method2">
    
  </a>
  <a name="method2">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">method2</span>(self, p_n, *args, **kwargs):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L536">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Smoothing method 2: Add 1 to both numerator and denominator from
Chin-Yew Lin and Franz Josef Och (2004) ORANGE: a Method for
Evaluating Automatic Evaluation Metrics for Machine Translation.
In COLING 2004.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.method3">
    
  </a>
  <a name="method3">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">method3</span>(self, p_n, *args, **kwargs):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L549">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Smoothing method 3: NIST geometric sequence smoothing
The smoothing is computed by taking 1 / ( 2^k ), instead of 0, for each
precision score whose matching n-gram count is null.
k is 1 for the first 'n' value for which the n-gram match count is null/
For example, if the text contains:
 - one 2-gram match
 - and (consequently) two 1-gram matches
the n-gram count for each individual precision score would be:
 - n=1  =&gt;  prec_count = 2     (two unigrams)
 - n=2  =&gt;  prec_count = 1     (one bigram)
 - n=3  =&gt;  prec_count = 1/2   (no trigram,  taking 'smoothed' value of 1 / ( 2^k ), with k=1)
 - n=4  =&gt;  prec_count = 1/4   (no fourgram, taking 'smoothed' value of 1 / ( 2^k ), with k=2)</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.method4">
    
  </a>
  <a name="method4">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">method4</span>(self, p_n, references, hypothesis, hyp_len=None, *args, **kwargs):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L571">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Smoothing method 4:
Shorter translations may have inflated precision values due to having
smaller denominators; therefore, we give them proportionally
smaller smoothed counts. Instead of scaling to 1/(2^k), Chen and Cherry
suggests dividing by 1/ln(len(T)), where T is the length of the translation.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.method5">
    
  </a>
  <a name="method5">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">method5</span>(self, p_n, references, hypothesis, hyp_len=None, *args, **kwargs):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L588">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Smoothing method 5:
The matched counts for similar values of n should be similar. To a
calculate the n-gram matched count, it averages the n−1, n and n+1 gram
matched counts.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.method6">
    
  </a>
  <a name="method6">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">method6</span>(self, p_n, references, hypothesis, hyp_len=None, *args, **kwargs):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L605">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Smoothing method 6:
Interpolates the maximum likelihood estimate of the precision *p_n* with
a prior estimate *pi0*. The prior is estimated by assuming that the ratio
between pn and pn−1 will be the same as that between pn−1 and pn−2; from
Gao and He (2013) Training MRF-Based Phrase Translation Models using
Gradient Ascent. In NAACL.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.translate.bleu_score.SmoothingFunction.method7">
    
  </a>
  <a name="method7">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">method7</span>(self, p_n, references, hypothesis, hyp_len=None, *args, **kwargs):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/translate/bleu_score.py#L632">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Smoothing method 7:
Interpolates methods 4 and 5.</p></div>
  </div>
</div>

      </div>
      <address>
        <a href="index.html">API Documentation</a> for <a href="https://github.com/tristanlatr/nltk">Natural Language Toolkit</a>, generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a> 21.2.2 at 2021-06-22 02:47:44.
      </address>

    </div>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>