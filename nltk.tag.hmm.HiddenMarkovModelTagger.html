<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>nltk.tag.hmm.HiddenMarkovModelTagger</title>
    <meta name="generator" content="pydoctor 21.2.2"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
          <span class="navbar-brand">
            <a href="https://github.com/tristanlatr/nltk" class="projecthome">Natural Language Toolkit</a> <a href="index.html">API Documentation</a>
          </span>

          <a href="moduleIndex.html">
            Modules
          </a>

          <a href="classIndex.html">
            Classes
          </a>

          <a href="nameIndex.html">
            Names
          </a>
      </div>

    </div>
  </div>
</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="nltk.html">nltk</a></code><wbr></wbr>.<code><a href="nltk.tag.html">tag</a></code><wbr></wbr>.<code><a href="nltk.tag.hmm.html">hmm</a></code><wbr></wbr>.<code><a href="nltk.tag.hmm.HiddenMarkovModelTagger.html">HiddenMarkovModelTagger</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">HiddenMarkovModelTagger</span>(<a href="nltk.tag.api.TaggerI.html" title="nltk.tag.api.TaggerI">TaggerI</a>): <a href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L104" class="sourceLink">(source)</a></code></p>
        <p><a href="classIndex.html#nltk.tag.hmm.HiddenMarkovModelTagger">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div><p>Hidden Markov model class, a generative model for labelling sequence data.
These models define the joint probability of a sequence of symbols and
their labels (state transitions) as the product of the starting state
probability, the probability of each state transition, and the probability
of each observation being generated from each state. This is described in
more detail in the module documentation.</p>
<p>This implementation is based on the HMM description in Chapter 8, Huang,
Acero and Hon, Spoken Language Processing and includes an extension for
training shallow HMM parsers or specialized HMMs as in Molina et.
al, 2002.  A specialized HMM modifies training data by applying a
specialization function to create a new training set that is more
appropriate for sequential tagging with an HMM.  A typical use case is
chunking.</p>
<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">symbols</span></td><td class="fieldArgDesc">the set of output symbols (alphabet)</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">states</span></td><td class="fieldArgDesc">a set of states representing state space</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">transitions</span></td><td class="fieldArgDesc">transition probabilities; Pr(s_i | s_j) is the
probability of transition from state i given the model is in
state_j</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">outputs</span></td><td class="fieldArgDesc">output probabilities; Pr(o_k | s_i) is the probability
of emitting symbol k when entering state i</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">priors</span></td><td class="fieldArgDesc">initial state distribution; Pr(s_i) is the probability
of starting in state i</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">transform</span></td><td class="fieldArgDesc">an optional function for transforming training
instances, defaults to the identity function.</td></tr></table></div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1559">
  
  
  <tr class="classmethod">
    
    <td>Class Method</td>
    <td><code><a href="#train">train</a></code></td>
    <td><span>Train a new HiddenMarkovModelTagger using the given labeled and unlabeled training instances. Testing will be performed if test instances are provided.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#__init__">__init__</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#__repr__">__repr__</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#best_path">best_path</a></code></td>
    <td><span>Returns the state sequence of the optimal (most probable) path through the HMM. Uses the Viterbi algorithm to calculate this part by dynamic programming.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#best_path_simple">best_path_simple</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#entropy">entropy</a></code></td>
    <td><span>Returns the entropy over labellings of the given sequence. This is given by:</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#log_probability">log_probability</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#point_entropy">point_entropy</a></code></td>
    <td><span>Returns the pointwise entropy over the possible states at each position in the chain, given the observation sequence.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#probability">probability</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#random_sample">random_sample</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#reset_cache">reset_cache</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#tag">tag</a></code></td>
    <td><span>Tags the sequence with the highest probability state sequence. This uses the best_path method to find the Viterbi path.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#test">test</a></code></td>
    <td><span>Tests the HiddenMarkovModelTagger instance.</span></td>
  </tr><tr class="classmethod private">
    
    <td>Class Method</td>
    <td><code><a href="#_train">_train</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_backward_probability">_backward_probability</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_best_path">_best_path</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_best_path_simple">_best_path_simple</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_create_cache">_create_cache</a></code></td>
    <td><span>The cache is a tuple (P, O, X, S) where:</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_exhaustive_entropy">_exhaustive_entropy</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_exhaustive_point_entropy">_exhaustive_point_entropy</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_forward_probability">_forward_probability</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_output_logprob">_output_logprob</a></code></td>
    <td><span></span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_outputs_vector">_outputs_vector</a></code></td>
    <td><span>Return a vector with log probabilities of emitting a symbol when entering states.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_sample_probdist">_sample_probdist</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_tag">_tag</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_transitions_matrix">_transitions_matrix</a></code></td>
    <td><span>Return a matrix of transition log probabilities.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_update_cache">_update_cache</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_cache">_cache</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_outputs">_outputs</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_priors">_priors</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_states">_states</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_symbols">_symbols</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_transform">_transform</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_transitions">_transitions</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr>
</table>
        
          <p class="inheritedFrom">
            Inherited from <code><a href="nltk.tag.api.TaggerI.html">TaggerI</a></code>:
          </p>
          <table class="children sortable" id="id1560">
  
  
  <tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tag.api.TaggerI.html#evaluate">evaluate</a></code></td>
    <td><span>Score the accuracy of the tagger against the gold standard. Strip the tags from the gold standard text, retag it using the tagger, then compute the accuracy score.</span></td>
  </tr><tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tag.api.TaggerI.html#tag_sents">tag_sents</a></code></td>
    <td><span>Apply <tt class="rst-docutils literal">self.tag()</tt> to each element of <em>sentences</em>.  I.e.:</span></td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tag.api.TaggerI.html#_check_params">_check_params</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr>
</table>
          

          
      </div>

      <div id="childList">

        <div class="baseclassmethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.train">
    
  </a>
  <a name="train">
    
  </a>
  <div class="functionHeader">
    @classmethod<br />
    <span class="py-keyword">def</span> <span class="py-defname">train</span>(cls, labeled_sequence, test_sequence=None, unlabeled_sequence=None, **kwargs):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L195">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Train a new HiddenMarkovModelTagger using the given labeled and
unlabeled training instances. Testing will be performed if test
instances are provided.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">labeled_sequence:</span>list(list)</td><td class="fieldArgDesc">a sequence of labeled training instances,
i.e. a list of sentences represented as tuples</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">test_sequence:</span>list(list)</td><td class="fieldArgDesc">a sequence of labeled test instances</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">unlabeled_sequence:</span>list(list)</td><td class="fieldArgDesc">a sequence of unlabeled training instances,
i.e. a list of sentences represented as words</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">kwargs</span></td><td class="fieldArgDesc"><span class="undocumented">Undocumented</span></td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">transform:</span>function</td><td class="fieldArgDesc">an optional function for transforming training
instances, defaults to the identity function, see <tt class="rst-docutils literal">transform()</tt></td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">estimator:</span>class or function</td><td class="fieldArgDesc">an optional function or class that maps a
condition's frequency distribution to its probability
distribution, defaults to a Lidstone distribution with gamma = 0.1</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">verbose:</span>bool</td><td class="fieldArgDesc">boolean flag indicating whether training should be
verbose or include printed output</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">max_iterations:</span>int</td><td class="fieldArgDesc">number of Baum-Welch interations to perform</td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">HiddenMarkovModelTagger</td><td class="fieldArgDesc">a hidden markov model tagger</td></tr></table></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.__init__">
    
  </a>
  <a name="__init__">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">__init__</span>(self, symbols, states, transitions, outputs, priors, transform=_identity):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L140">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.__repr__">
    
  </a>
  <a name="__repr__">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">__repr__</span>(self):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L831">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.best_path">
    
  </a>
  <a name="best_path">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">best_path</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L374">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Returns the state sequence of the optimal (most probable) path through
the HMM. Uses the Viterbi algorithm to calculate this part by dynamic
programming.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">unlabeled_sequence:</span>list</td><td class="fieldArgDesc">the sequence of unlabeled symbols</td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">sequence of any</td><td class="fieldArgDesc">the state sequence</td></tr></table></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.best_path_simple">
    
  </a>
  <a name="best_path_simple">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">best_path_simple</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L416">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Returns the state sequence of the optimal (most probable) path through
the HMM. Uses the Viterbi algorithm to calculate this part by dynamic
programming.  This uses a simple, direct method, and is included for
teaching purposes.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">unlabeled_sequence:</span>list</td><td class="fieldArgDesc">the sequence of unlabeled symbols</td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">sequence of any</td><td class="fieldArgDesc">the state sequence</td></tr></table></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.entropy">
    
  </a>
  <a name="entropy">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">entropy</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L524">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p>Returns the entropy over labellings of the given sequence. This is
given by:</p>
<pre class="rst-literal-block">
H(O) = - sum_S Pr(S | O) log Pr(S | O)
</pre>
<p>where the summation ranges over all state sequences, S. Let
<em>Z = Pr(O) = sum_S Pr(S, O)}</em> where the summation ranges over all state
sequences and O is the observation sequence. As such the entropy can
be re-expressed as:</p>
<pre class="rst-literal-block">
H = - sum_S Pr(S | O) log [ Pr(S, O) / Z ]
= log Z - sum_S Pr(S | O) log Pr(S, 0)
= log Z - sum_S Pr(S | O) [ log Pr(S_0) + sum_t Pr(S_t | S_{t-1}) + sum_t Pr(O_t | S_t) ]
</pre>
<p>The order of summation for the log terms can be flipped, allowing
dynamic programming to be used to calculate the entropy. Specifically,
we use the forward and backward probabilities (alpha, beta) giving:</p>
<pre class="rst-literal-block">
H = log Z - sum_s0 alpha_0(s0) beta_0(s0) / Z * log Pr(s0)
+ sum_t,si,sj alpha_t(si) Pr(sj | si) Pr(O_t+1 | sj) beta_t(sj) / Z * log Pr(sj | si)
+ sum_t,st alpha_t(st) beta_t(st) / Z * log Pr(O_t | st)
</pre>
<p>This simply uses alpha and beta to find the probabilities of partial
sequences, constrained to include the given state(s) at some point in
time.</p>
</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.log_probability">
    
  </a>
  <a name="log_probability">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">log_probability</span>(self, sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L244">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Returns the log-probability of the given symbol sequence. If the
sequence is labelled, then returns the joint log-probability of the
symbol, state sequence. Otherwise, uses the forward algorithm to find
the log-probability over all label sequences.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">sequence:</span>Token</td><td class="fieldArgDesc">the sequence of symbols which must contain the TEXT
property, and optionally the TAG property</td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">float</td><td class="fieldArgDesc">the log-probability of the sequence</td></tr></table></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.point_entropy">
    
  </a>
  <a name="point_entropy">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">point_entropy</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L595">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Returns the pointwise entropy over the possible states at each
position in the chain, given the observation sequence.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.probability">
    
  </a>
  <a name="probability">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">probability</span>(self, sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L229">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Returns the probability of the given symbol sequence. If the sequence
is labelled, then returns the joint probability of the symbol, state
sequence. Otherwise, uses the forward algorithm to find the
probability over all label sequences.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">sequence:</span>Token</td><td class="fieldArgDesc">the sequence of symbols which must contain the TEXT
property, and optionally the TAG property</td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">float</td><td class="fieldArgDesc">the probability of the sequence</td></tr></table></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.random_sample">
    
  </a>
  <a name="random_sample">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">random_sample</span>(self, rng, length):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L475">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Randomly sample the HMM to generate a sentence of a given length. This
samples the prior distribution then the observation distribution and
transition distribution for each subsequent observation and state.
This will mostly generate unintelligible garbage, but can provide some
amusement.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">rng:</span>Random (or any object with a random() method)</td><td class="fieldArgDesc">random number generator</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">length:</span>int</td><td class="fieldArgDesc">desired output length</td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">list</td><td class="fieldArgDesc">the randomly created state/observation sequence,
generated according to the HMM's probability
distributions. The SUBTOKENS have TEXT and TAG
properties containing the observation and state
respectively.</td></tr></table></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.reset_cache">
    
  </a>
  <a name="reset_cache">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">reset_cache</span>(self):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L371">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.tag">
    
  </a>
  <a name="tag">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">tag</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L278">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tag.api.TaggerI.html#tag">nltk.tag.api.TaggerI.tag</a></code></div>
    
    <div>Tags the sequence with the highest probability state sequence. This
uses the best_path method to find the Viterbi path.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">unlabeled_sequence:</span>list</td><td class="fieldArgDesc">the sequence of unlabeled symbols</td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">list</td><td class="fieldArgDesc">a labelled sequence of symbols</td></tr></table></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger.test">
    
  </a>
  <a name="test">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">test</span>(self, test_sequence, verbose=False, **kwargs):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L780">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Tests the HiddenMarkovModelTagger instance.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">test_sequence:</span>list(list)</td><td class="fieldArgDesc">a sequence of labeled test instances</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">verbose:</span>bool</td><td class="fieldArgDesc">boolean flag indicating whether training should be
verbose or include printed output</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">kwargs</span></td><td class="fieldArgDesc"><span class="undocumented">Undocumented</span></td></tr></table></div>
  </div>
</div><div class="baseclassmethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._train">
    
  </a>
  <a name="_train">
    
  </a>
  <div class="functionHeader">
    @classmethod<br />
    <span class="py-keyword">def</span> <span class="py-defname">_train</span>(cls, labeled_sequence, test_sequence=None, unlabeled_sequence=None, transform=_identity, estimator=None, **kwargs):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L151">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._backward_probability">
    
  </a>
  <a name="_backward_probability">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_backward_probability</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L746">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Return the backward probability matrix, a T by N array of
log-probabilities, where T is the length of the sequence and N is the
number of states. Each entry (t, s) gives the probability of being in
state s at time t after observing the partial symbol sequence from t
.. T.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">unlabeled_sequence:</span>list</td><td class="fieldArgDesc">the sequence of unlabeled symbols</td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">array</td><td class="fieldArgDesc">the backward log probability matrix</td></tr></table></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._best_path">
    
  </a>
  <a name="_best_path">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_best_path</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L388">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._best_path_simple">
    
  </a>
  <a name="_best_path_simple">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_best_path_simple</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L431">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._create_cache">
    
  </a>
  <a name="_create_cache">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_create_cache</span>(self):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L303">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p>The cache is a tuple (P, O, X, S) where:</p>
<blockquote>
<ul>
<li><p class="rst-first">S maps symbols to integers.  I.e., it is the inverse
mapping from self._symbols; for each symbol s in
self._symbols, the following is true:</p>
<pre class="rst-literal-block">
self._symbols[S[s]] == s
</pre>
</li>
<li><p class="rst-first">O is the log output probabilities:</p>
<pre class="rst-literal-block">
O[i,k] = log( P(token[t]=sym[k]|tag[t]=state[i]) )
</pre>
</li>
<li><p class="rst-first">X is the log transition probabilities:</p>
<pre class="rst-literal-block">
X[i,j] = log( P(tag[t]=state[j]|tag[t-1]=state[i]) )
</pre>
</li>
<li><p class="rst-first">P is the log prior probabilities:</p>
<pre class="rst-literal-block">
P[i] = log( P(tag[0]=state[i]) )
</pre>
</li>
</ul>
</blockquote>
</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._exhaustive_entropy">
    
  </a>
  <a name="_exhaustive_entropy">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_exhaustive_entropy</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L620">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._exhaustive_point_entropy">
    
  </a>
  <a name="_exhaustive_point_entropy">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_exhaustive_point_entropy</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L650">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._forward_probability">
    
  </a>
  <a name="_forward_probability">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_forward_probability</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L709">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Return the forward probability matrix, a T by N array of
log-probabilities, where T is the length of the sequence and N is the
number of states. Each entry (t, s) gives the probability of being in
state s at time t after observing the partial symbol sequence up to
and including t.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">unlabeled_sequence:</span>list</td><td class="fieldArgDesc">the sequence of unlabeled symbols</td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">array</td><td class="fieldArgDesc">the forward log probability matrix</td></tr></table></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._output_logprob">
    
  </a>
  <a name="_output_logprob">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_output_logprob</span>(self, state, symbol):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L295">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">float</td><td class="fieldArgDesc">the log probability of the symbol being observed in the given
state</td></tr></table></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._outputs_vector">
    
  </a>
  <a name="_outputs_vector">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_outputs_vector</span>(self, symbol):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L701">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Return a vector with log probabilities of emitting a symbol
when entering states.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._sample_probdist">
    
  </a>
  <a name="_sample_probdist">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_sample_probdist</span>(self, probdist, p, samples):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L515">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._tag">
    
  </a>
  <a name="_tag">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_tag</span>(self, unlabeled_sequence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L291">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._transitions_matrix">
    
  </a>
  <a name="_transitions_matrix">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_transitions_matrix</span>(self):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L689">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Return a matrix of transition log probabilities.</div>
  </div>
</div><div class="basemethod private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._update_cache">
    
  </a>
  <a name="_update_cache">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_update_cache</span>(self, symbols):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L343">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._cache">
    
  </a>
  <a name="_cache">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_cache</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L148">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._outputs">
    
  </a>
  <a name="_outputs">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_outputs</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L146">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._priors">
    
  </a>
  <a name="_priors">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_priors</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L147">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._states">
    
  </a>
  <a name="_states">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_states</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L144">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._symbols">
    
  </a>
  <a name="_symbols">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_symbols</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L143">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._transform">
    
  </a>
  <a name="_transform">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_transform</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L149">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  
  <a name="nltk.tag.hmm.HiddenMarkovModelTagger._transitions">
    
  </a>
  <a name="_transitions">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_transitions</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tag/hmm.py#L145">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div>

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for <a href="https://github.com/tristanlatr/nltk" class="projecthome">Natural Language Toolkit</a>,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    21.2.2 at 2021-06-22 02:56:13.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>