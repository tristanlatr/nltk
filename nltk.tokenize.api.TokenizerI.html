<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>nltk.tokenize.api.TokenizerI</title>
    <meta name="generator" content="pydoctor 21.2.2"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
          <span class="navbar-brand">
            <a href="https://github.com/tristanlatr/nltk" class="projecthome">Natural Language Toolkit</a> <a href="index.html">API Documentation</a>
          </span>

          <a href="moduleIndex.html">
            Modules
          </a>

          <a href="classIndex.html">
            Classes
          </a>

          <a href="nameIndex.html">
            Names
          </a>
      </div>

    </div>
  </div>
</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="nltk.html">nltk</a></code><wbr></wbr>.<code><a href="nltk.tokenize.html">tokenize</a></code><wbr></wbr>.<code><a href="nltk.tokenize.api.html">api</a></code><wbr></wbr>.<code><a href="nltk.tokenize.api.TokenizerI.html">TokenizerI</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">TokenizerI</span>(<a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC">ABC</a>): <a href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/api.py#L19" class="sourceLink">(source)</a></code></p><p>Known subclasses: <code><a href="nltk.parse.corenlp.GenericCoreNLPParser.html">nltk.parse.corenlp.GenericCoreNLPParser</a></code>, <code><a href="nltk.tokenize.api.StringTokenizer.html">nltk.tokenize.api.StringTokenizer</a></code>, <code><a href="nltk.tokenize.destructive.NLTKWordTokenizer.html">nltk.tokenize.destructive.NLTKWordTokenizer</a></code>, <code><a href="nltk.tokenize.mwe.MWETokenizer.html">nltk.tokenize.mwe.MWETokenizer</a></code>, <code><a href="nltk.tokenize.nist.NISTTokenizer.html">nltk.tokenize.nist.NISTTokenizer</a></code>, <code><a href="nltk.tokenize.punkt.PunktSentenceTokenizer.html">nltk.tokenize.punkt.PunktSentenceTokenizer</a></code>, <code><a href="nltk.tokenize.regexp.RegexpTokenizer.html">nltk.tokenize.regexp.RegexpTokenizer</a></code>, <code><a href="nltk.tokenize.repp.ReppTokenizer.html">nltk.tokenize.repp.ReppTokenizer</a></code>, <code><a href="nltk.tokenize.sexpr.SExprTokenizer.html">nltk.tokenize.sexpr.SExprTokenizer</a></code>, <code><a href="nltk.tokenize.simple.LineTokenizer.html">nltk.tokenize.simple.LineTokenizer</a></code>, <code><a href="nltk.tokenize.sonority_sequencing.SyllableTokenizer.html">nltk.tokenize.sonority_sequencing.SyllableTokenizer</a></code>, <code><a href="nltk.tokenize.stanford.StanfordTokenizer.html">nltk.tokenize.stanford.StanfordTokenizer</a></code>, <code><a href="nltk.tokenize.stanford_segmenter.StanfordSegmenter.html">nltk.tokenize.stanford_segmenter.StanfordSegmenter</a></code>, <code><a href="nltk.tokenize.texttiling.TextTilingTokenizer.html">nltk.tokenize.texttiling.TextTilingTokenizer</a></code>, <code><a href="nltk.tokenize.toktok.ToktokTokenizer.html">nltk.tokenize.toktok.ToktokTokenizer</a></code>, <code><a href="nltk.tokenize.treebank.TreebankWordDetokenizer.html">nltk.tokenize.treebank.TreebankWordDetokenizer</a></code>, <code><a href="nltk.tokenize.treebank.TreebankWordTokenizer.html">nltk.tokenize.treebank.TreebankWordTokenizer</a></code></p>
        <p><a href="classIndex.html#nltk.tokenize.api.TokenizerI">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div><p class="pre">A processing interface for tokenizing a string.
Subclasses must define ``tokenize()`` or ``tokenize_sents()`` (or both).</p></div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1778">
  
  
  <tr class="method">
    
    <td>Method</td>
    <td><code><a href="#span_tokenize">span_tokenize</a></code></td>
    <td><span>Identify the tokens using integer offsets ``(start_i, end_i)``, where ``s[start_i:end_i]`` is the corresponding token.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#span_tokenize_sents">span_tokenize_sents</a></code></td>
    <td><span>Apply ``self.span_tokenize()`` to each element of ``strings``.  I.e.:</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#tokenize">tokenize</a></code></td>
    <td><span>Return a tokenized copy of *s*.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#tokenize_sents">tokenize_sents</a></code></td>
    <td><span>Apply ``self.tokenize()`` to each element of ``strings``.  I.e.:</span></td>
  </tr>
</table>
        

          
      </div>

      <div id="childList">

        <div class="basemethod">
  
  
  <a name="nltk.tokenize.api.TokenizerI.span_tokenize">
    
  </a>
  <a name="span_tokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">span_tokenize</span>(self, s):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/api.py#L35">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overridden in <code><a href="nltk.tokenize.api.StringTokenizer.html">nltk.tokenize.api.StringTokenizer</a></code>, <code><a href="nltk.tokenize.punkt.PunktSentenceTokenizer.html">nltk.tokenize.punkt.PunktSentenceTokenizer</a></code>, <code><a href="nltk.tokenize.regexp.RegexpTokenizer.html">nltk.tokenize.regexp.RegexpTokenizer</a></code>, <code><a href="nltk.tokenize.simple.LineTokenizer.html">nltk.tokenize.simple.LineTokenizer</a></code>, <code><a href="nltk.tokenize.treebank.TreebankWordTokenizer.html">nltk.tokenize.treebank.TreebankWordTokenizer</a></code></div>
    
    <div><p class="pre">Identify the tokens using integer offsets ``(start_i, end_i)``,
where ``s[start_i:end_i]`` is the corresponding token.

:rtype: iter(tuple(int, int))</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.api.TokenizerI.span_tokenize_sents">
    
  </a>
  <a name="span_tokenize_sents">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">span_tokenize_sents</span>(self, strings):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/api.py#L54">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Apply ``self.span_tokenize()`` to each element of ``strings``.  I.e.:

    return [self.span_tokenize(s) for s in strings]

:rtype: iter(list(tuple(int, int)))</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.api.TokenizerI.tokenize">
    
  </a>
  <a name="tokenize">
    
  </a>
  <div class="functionHeader">
    @abstractmethod<br />
    <span class="py-keyword">def</span> <span class="py-defname">tokenize</span>(self, s):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/api.py#L25">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overridden in <code><a href="nltk.parse.corenlp.GenericCoreNLPParser.html">nltk.parse.corenlp.GenericCoreNLPParser</a></code>, <code><a href="nltk.tokenize.api.StringTokenizer.html">nltk.tokenize.api.StringTokenizer</a></code>, <code><a href="nltk.tokenize.destructive.NLTKWordTokenizer.html">nltk.tokenize.destructive.NLTKWordTokenizer</a></code>, <code><a href="nltk.tokenize.mwe.MWETokenizer.html">nltk.tokenize.mwe.MWETokenizer</a></code>, <code><a href="nltk.tokenize.nist.NISTTokenizer.html">nltk.tokenize.nist.NISTTokenizer</a></code>, <code><a href="nltk.tokenize.punkt.PunktSentenceTokenizer.html">nltk.tokenize.punkt.PunktSentenceTokenizer</a></code>, <code><a href="nltk.tokenize.regexp.RegexpTokenizer.html">nltk.tokenize.regexp.RegexpTokenizer</a></code>, <code><a href="nltk.tokenize.repp.ReppTokenizer.html">nltk.tokenize.repp.ReppTokenizer</a></code>, <code><a href="nltk.tokenize.sexpr.SExprTokenizer.html">nltk.tokenize.sexpr.SExprTokenizer</a></code>, <code><a href="nltk.tokenize.simple.LineTokenizer.html">nltk.tokenize.simple.LineTokenizer</a></code>, <code><a href="nltk.tokenize.sonority_sequencing.SyllableTokenizer.html">nltk.tokenize.sonority_sequencing.SyllableTokenizer</a></code>, <code><a href="nltk.tokenize.stanford.StanfordTokenizer.html">nltk.tokenize.stanford.StanfordTokenizer</a></code>, <code><a href="nltk.tokenize.stanford_segmenter.StanfordSegmenter.html">nltk.tokenize.stanford_segmenter.StanfordSegmenter</a></code>, <code><a href="nltk.tokenize.texttiling.TextTilingTokenizer.html">nltk.tokenize.texttiling.TextTilingTokenizer</a></code>, <code><a href="nltk.tokenize.toktok.ToktokTokenizer.html">nltk.tokenize.toktok.ToktokTokenizer</a></code>, <code><a href="nltk.tokenize.treebank.TreebankWordDetokenizer.html">nltk.tokenize.treebank.TreebankWordDetokenizer</a></code>, <code><a href="nltk.tokenize.treebank.TreebankWordTokenizer.html">nltk.tokenize.treebank.TreebankWordTokenizer</a></code></div>
    
    <div><p class="pre">Return a tokenized copy of *s*.

:rtype: list of str</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.api.TokenizerI.tokenize_sents">
    
  </a>
  <a name="tokenize_sents">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">tokenize_sents</span>(self, strings):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/api.py#L44">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overridden in <code><a href="nltk.tokenize.repp.ReppTokenizer.html">nltk.tokenize.repp.ReppTokenizer</a></code></div>
    
    <div><p class="pre">Apply ``self.tokenize()`` to each element of ``strings``.  I.e.:

    return [self.tokenize(s) for s in strings]

:rtype: list(list(str))</p></div>
  </div>
</div>

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for <a href="https://github.com/tristanlatr/nltk" class="projecthome">Natural Language Toolkit</a>,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    21.2.2 at 2021-06-22 02:51:08.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>