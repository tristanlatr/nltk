<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  <head>
    <title>nltk.tokenize.punkt.PunktTrainer : API documentation</title>

    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
  </head>
  <body>

    <nav class="navbar navbar-default">
      <div class="container">
        <div class="navbar-header navbar-brand">
          <a href="https://github.com/tristanlatr/nltk">Natural Language Toolkit</a>
          <a href="index.html">API Documentation</a>
        </div>
      </div>
    </nav>

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="nltk.html">nltk</a></code>.<code><a href="nltk.tokenize.html">tokenize</a></code>.<code><a href="nltk.tokenize.punkt.html">punkt</a></code>.<code><a href="nltk.tokenize.punkt.PunktTrainer.html">PunktTrainer</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">PunktTrainer</span>(<a href="nltk.tokenize.punkt.PunktBaseClass.html" title="nltk.tokenize.punkt.PunktBaseClass">PunktBaseClass</a>): <a href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L629">(source)</a></code></p>
        <p><a href="classIndex.html#nltk.tokenize.punkt.PunktTrainer">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div><p class="pre">Learns parameters used in Punkt sentence boundary detection.</p></div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1794">
  
  <tr class="method">
    
    <td>Method</td>
    <td><code><a href="#__init__">__init__</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#get_params">get_params</a></code></td>
    <td><span>Calculates and returns parameters for sentence boundary detection as derived from training.</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#ABBREV">ABBREV</a></code></td>
    <td><span>cut-off value whether a 'token' is an abbreviation</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#IGNORE_ABBREV_PENALTY">IGNORE_ABBREV_PENALTY</a></code></td>
    <td><span>allows the disabling of the abbreviation penalty heuristic, which exponentially disadvantages words that are found at times without a final period.</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#ABBREV_BACKOFF">ABBREV_BACKOFF</a></code></td>
    <td><span>upper cut-off for Mikheev's(2002) abbreviation detection algorithm</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#COLLOCATION">COLLOCATION</a></code></td>
    <td><span>minimal log-likelihood value that two tokens need to be considered as a collocation</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#SENT_STARTER">SENT_STARTER</a></code></td>
    <td><span>minimal log-likelihood value that a token requires to be considered as a frequent sentence starter</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#INCLUDE_ALL_COLLOCS">INCLUDE_ALL_COLLOCS</a></code></td>
    <td><span>this includes as potential collocations all word pairs where the first word ends in a period. It may be useful in corpora where there is a lot of variation that makes abbreviations like Mr difficult to identify.</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#INCLUDE_ABBREV_COLLOCS">INCLUDE_ABBREV_COLLOCS</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#MIN_COLLOC_FREQ">MIN_COLLOC_FREQ</a></code></td>
    <td><span>this sets a minimum bound on the number of times a bigram needs to appear before it can be considered a collocation, in addition to log likelihood statistics. This is useful when INCLUDE_ALL_COLLOCS is True.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#train">train</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#train_tokens">train_tokens</a></code></td>
    <td><span>Collects training data from a given list of tokens.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#finalize_training">finalize_training</a></code></td>
    <td><span>Uses data that has been gathered in training to determine likely collocations and sentence starters.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#freq_threshold">freq_threshold</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#find_abbrev_types">find_abbrev_types</a></code></td>
    <td><span>Recalculates abbreviations given type frequencies, despite no prior determination of abbreviations. This fails to include abbreviations otherwise found as "rare".</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_type_fdist">_type_fdist</a></code></td>
    <td><span>A frequency distribution giving the frequency of each case-normalized token type in the training data.</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_num_period_toks">_num_period_toks</a></code></td>
    <td><span>The number of words ending in period in the training data.</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_collocation_fdist">_collocation_fdist</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_sent_starter_fdist">_sent_starter_fdist</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_sentbreak_count">_sentbreak_count</a></code></td>
    <td><span>The total number of sentence breaks identified in training, used for calculating the frequent sentence starter heuristic.</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_finalized">_finalized</a></code></td>
    <td><span>A flag as to whether the training has been finalized by finding collocations and sentence starters, or whether finalize_training() still needs to be called.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_train_tokens">_train_tokens</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_unique_types">_unique_types</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_freq_threshold">_freq_threshold</a></code></td>
    <td><span>Returns a FreqDist containing only data with counts below a given threshold, as well as a mapping (None -&gt; count_removed).</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_get_orthography_data">_get_orthography_data</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_reclassify_abbrev_types">_reclassify_abbrev_types</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_is_rare_abbrev_type">_is_rare_abbrev_type</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="staticmethod private">
    
    <td>Static Method</td>
    <td><code><a href="#_dunning_log_likelihood">_dunning_log_likelihood</a></code></td>
    <td><span>A function that calculates the modified Dunning log-likelihood ratio scores for abbreviation candidates.  The details of how this works is available in the paper.</span></td>
  </tr><tr class="staticmethod private">
    
    <td>Static Method</td>
    <td><code><a href="#_col_log_likelihood">_col_log_likelihood</a></code></td>
    <td><span>A function that will just compute log-likelihood estimate, in the original paper it's described in algorithm 6 and 7.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_is_potential_collocation">_is_potential_collocation</a></code></td>
    <td><span>Returns True if the pair of tokens may form a collocation given log-likelihood statistics.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_find_collocations">_find_collocations</a></code></td>
    <td><span>Generates likely collocations and their log-likelihood.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_is_potential_sent_starter">_is_potential_sent_starter</a></code></td>
    <td><span>Returns True given a token and the token that preceds it if it seems clear that the token is beginning a sentence.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_find_sent_starters">_find_sent_starters</a></code></td>
    <td><span>Uses collocation heuristics for each candidate token to determine if it frequently starts sentences.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_get_sentbreak_count">_get_sentbreak_count</a></code></td>
    <td><span>Returns the number of sentence breaks marked in a given set of augmented tokens.</span></td>
  </tr>
</table>
        
          <p class="inheritedFrom">
            Inherited from <code><a href="nltk.tokenize.punkt.PunktBaseClass.html">PunktBaseClass</a></code>:
          </p>
          <table class="children sortable" id="id1795">
  
  <tr class="baseinstancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_params">_params</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="baseinstancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_lang_vars">_lang_vars</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="baseinstancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_Token">_Token</a></code></td>
    <td><span>The collection of parameters that determines the behavior of the punkt tokenizer.</span></td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_tokenize_words">_tokenize_words</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_annotate_first_pass">_annotate_first_pass</a></code></td>
    <td><span>Perform the first pass of annotation, which makes decisions based purely based on the word type of each word:</span></td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_first_pass_annotation">_first_pass_annotation</a></code></td>
    <td><span>Performs type-based annotation on a single token.</span></td>
  </tr>
</table>
          

          
      </div>

      <div id="childList">

        <div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.__init__">
    
  </a>
  <a name="__init__">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">__init__</span>(self, train_text=None, verbose=False, lang_vars=None, token_cls=PunktToken):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L632">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.punkt.PunktBaseClass.html#__init__">nltk.tokenize.punkt.PunktBaseClass.__init__</a></code></div>
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._type_fdist">
    
  </a>
  <a name="_type_fdist">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_type_fdist</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L638">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">A frequency distribution giving the frequency of each
case-normalized token type in the training data.</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._num_period_toks">
    
  </a>
  <a name="_num_period_toks">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_num_period_toks</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L642">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">The number of words ending in period in the training data.</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
  </div>
</div><div class="baseinstancevariable private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._collocation_fdist">
    
  </a>
  <a name="_collocation_fdist">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_collocation_fdist</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L645">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">A frequency distribution giving the frequency of all
bigrams in the training data where the first word ends in a
period.  Bigrams are encoded as tuples of word types.
Especially common collocations are extracted from this
frequency distribution, and stored in
``_params``.``collocations &lt;PunktParameters.collocations&gt;``.</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._sent_starter_fdist">
    
  </a>
  <a name="_sent_starter_fdist">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_sent_starter_fdist</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L653">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">A frequency distribution giving the frequency of all words
that occur at the training data at the beginning of a sentence
(after the first pass of annotation).  Especially common
sentence starters are extracted from this frequency
distribution, and stored in ``_params.sent_starters``.</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._sentbreak_count">
    
  </a>
  <a name="_sentbreak_count">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_sentbreak_count</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L661">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">The total number of sentence breaks identified in training, used for
calculating the frequent sentence starter heuristic.</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
  </div>
</div><div class="baseinstancevariable private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._finalized">
    
  </a>
  <a name="_finalized">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_finalized</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L665">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">A flag as to whether the training has been finalized by finding
collocations and sentence starters, or whether finalize_training()
still needs to be called.</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>)
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.get_params">
    
  </a>
  <a name="get_params">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">get_params</span>(self):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L673">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Calculates and returns parameters for sentence boundary detection as
derived from training.</p></div>
  </div>
</div><div class="baseclassvariable">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.ABBREV">
    
  </a>
  <a name="ABBREV">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">ABBREV</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L685">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">cut-off value whether a 'token' is an abbreviation</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#float">float</a></code>)
  </div>
</div><div class="baseclassvariable">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.IGNORE_ABBREV_PENALTY">
    
  </a>
  <a name="IGNORE_ABBREV_PENALTY">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">IGNORE_ABBREV_PENALTY</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L688">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">allows the disabling of the abbreviation penalty heuristic, which
exponentially disadvantages words that are found at times without a
final period.</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>)
  </div>
</div><div class="baseclassvariable">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.ABBREV_BACKOFF">
    
  </a>
  <a name="ABBREV_BACKOFF">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">ABBREV_BACKOFF</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L693">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">upper cut-off for Mikheev's(2002) abbreviation detection algorithm</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
  </div>
</div><div class="baseclassvariable">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.COLLOCATION">
    
  </a>
  <a name="COLLOCATION">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">COLLOCATION</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L696">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">minimal log-likelihood value that two tokens need to be considered
as a collocation</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#float">float</a></code>)
  </div>
</div><div class="baseclassvariable">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.SENT_STARTER">
    
  </a>
  <a name="SENT_STARTER">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">SENT_STARTER</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L700">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">minimal log-likelihood value that a token requires to be considered
as a frequent sentence starter</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
  </div>
</div><div class="baseclassvariable">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.INCLUDE_ALL_COLLOCS">
    
  </a>
  <a name="INCLUDE_ALL_COLLOCS">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">INCLUDE_ALL_COLLOCS</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L704">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">this includes as potential collocations all word pairs where the first
word ends in a period. It may be useful in corpora where there is a lot
of variation that makes abbreviations like Mr difficult to identify.</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>)
  </div>
</div><div class="baseclassvariable">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.INCLUDE_ABBREV_COLLOCS">
    
  </a>
  <a name="INCLUDE_ABBREV_COLLOCS">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">INCLUDE_ABBREV_COLLOCS</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L709">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">this includes as potential collocations all word pairs where the first
word is an abbreviation. Such collocations override the orthographic
heuristic, but not the sentence starter heuristic. This is overridden by
INCLUDE_ALL_COLLOCS, and if both are false, only collocations with initials
and ordinals are considered.</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>)
  </div>
</div><div class="baseclassvariable">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.MIN_COLLOC_FREQ">
    
  </a>
  <a name="MIN_COLLOC_FREQ">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">MIN_COLLOC_FREQ</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L717">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="pre">this sets a minimum bound on the number of times a bigram needs to
appear before it can be considered a collocation, in addition to log
likelihood statistics. This is useful when INCLUDE_ALL_COLLOCS is True.</p></div> (type: <code><a href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.train">
    
  </a>
  <a name="train">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">train</span>(self, text, verbose=False, finalize=True):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L726">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Collects training data from a given text. If finalize is True, it
will determine all the parameters for sentence boundary detection. If
not, this will be delayed until get_params() or finalize_training() is
called. If verbose is True, abbreviations found will be listed.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.train_tokens">
    
  </a>
  <a name="train_tokens">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">train_tokens</span>(self, tokens, verbose=False, finalize=True):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L739">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Collects training data from a given list of tokens.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._train_tokens">
    
  </a>
  <a name="_train_tokens">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_train_tokens</span>(self, tokens, verbose):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L747">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._unique_types">
    
  </a>
  <a name="_unique_types">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_unique_types</span>(self, tokens):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L808">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.finalize_training">
    
  </a>
  <a name="finalize_training">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">finalize_training</span>(self, verbose=False):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L811">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Uses data that has been gathered in training to determine likely
collocations and sentence starters.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.freq_threshold">
    
  </a>
  <a name="freq_threshold">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">freq_threshold</span>(self, ortho_thresh=2, type_thresh=2, colloc_thres=2, sentstart_thresh=2):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L834">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Allows memory use to be reduced after much training by removing data
about rare tokens that are unlikely to have a statistical effect with
further training. Entries occurring above the given thresholds will be
retained.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._freq_threshold">
    
  </a>
  <a name="_freq_threshold">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_freq_threshold</span>(self, fdist, threshold):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L859">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Returns a FreqDist containing only data with counts below a given
threshold, as well as a mapping (None -&gt; count_removed).</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._get_orthography_data">
    
  </a>
  <a name="_get_orthography_data">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_get_orthography_data</span>(self, tokens):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L881">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Collect information about whether each token type occurs
with different case patterns (i) overall, (ii) at
sentence-initial positions, and (iii) at sentence-internal
positions.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._reclassify_abbrev_types">
    
  </a>
  <a name="_reclassify_abbrev_types">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_reclassify_abbrev_types</span>(self, types):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L929">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">(Re)classifies each given token if
  - it is period-final and not a known abbreviation; or
  - it is not period-final and is otherwise a known abbreviation
by checking whether its previous classification still holds according
to the heuristics of section 3.
Yields triples (abbr, score, is_add) where abbr is the type in question,
score is its log-likelihood with penalties applied, and is_add specifies
whether the present type is a candidate for inclusion or exclusion as an
abbreviation, such that:
  - (is_add and score &gt;= 0.3)    suggests a new abbreviation; and
  - (not is_add and score &lt; 0.3) suggests excluding an abbreviation.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktTrainer.find_abbrev_types">
    
  </a>
  <a name="find_abbrev_types">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">find_abbrev_types</span>(self):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L996">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Recalculates abbreviations given type frequencies, despite no prior
determination of abbreviations.
This fails to include abbreviations otherwise found as "rare".</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._is_rare_abbrev_type">
    
  </a>
  <a name="_is_rare_abbrev_type">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_is_rare_abbrev_type</span>(self, cur_tok, next_tok):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1011">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">A word type is counted as a rare abbreviation if...
  - it's not already marked as an abbreviation
  - it occurs fewer than ABBREV_BACKOFF times
  - either it is followed by a sentence-internal punctuation
    mark, *or* it is followed by a lower-case word that
    sometimes appears with upper case, but never occurs with
    lower case at the beginning of sentences.</p></div>
  </div>
</div><div class="basestaticmethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._dunning_log_likelihood">
    
  </a>
  <a name="_dunning_log_likelihood">
    
  </a>
  <div class="functionHeader">
    @staticmethod<br />
    <span class="py-keyword">def</span> <span class="py-defname">_dunning_log_likelihood</span>(count_a, count_b, count_ab, N):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1059">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">A function that calculates the modified Dunning log-likelihood
ratio scores for abbreviation candidates.  The details of how
this works is available in the paper.</p></div>
  </div>
</div><div class="basestaticmethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._col_log_likelihood">
    
  </a>
  <a name="_col_log_likelihood">
    
  </a>
  <div class="functionHeader">
    @staticmethod<br />
    <span class="py-keyword">def</span> <span class="py-defname">_col_log_likelihood</span>(count_a, count_b, count_ab, N):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1076">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">A function that will just compute log-likelihood estimate, in
the original paper it's described in algorithm 6 and 7.

This *should* be the original Dunning log-likelihood values,
unlike the previous log_l function where it used modified
Dunning log-likelihood values</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._is_potential_collocation">
    
  </a>
  <a name="_is_potential_collocation">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_is_potential_collocation</span>(self, aug_tok1, aug_tok2):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1127">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Returns True if the pair of tokens may form a collocation given
log-likelihood statistics.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._find_collocations">
    
  </a>
  <a name="_find_collocations">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_find_collocations</span>(self):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1142">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Generates likely collocations and their log-likelihood.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._is_potential_sent_starter">
    
  </a>
  <a name="_is_potential_sent_starter">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_is_potential_sent_starter</span>(self, cur_tok, prev_tok):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1177">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Returns True given a token and the token that preceds it if it
seems clear that the token is beginning a sentence.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._find_sent_starters">
    
  </a>
  <a name="_find_sent_starters">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_find_sent_starters</span>(self):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1191">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Uses collocation heuristics for each candidate token to
determine if it frequently starts sentences.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktTrainer._get_sentbreak_count">
    
  </a>
  <a name="_get_sentbreak_count">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_get_sentbreak_count</span>(self, tokens):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1220">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Returns the number of sentence breaks marked in a given set of
augmented tokens.</p></div>
  </div>
</div>

      </div>
      <address>
        <a href="index.html">API Documentation</a> for <a href="https://github.com/tristanlatr/nltk">Natural Language Toolkit</a>, generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a> 21.2.2 at 2021-06-22 02:47:44.
      </address>

    </div>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>