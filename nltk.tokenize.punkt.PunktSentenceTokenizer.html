<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  <head>
    <title>nltk.tokenize.punkt.PunktSentenceTokenizer : API documentation</title>

    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
  </head>
  <body>

    <nav class="navbar navbar-default">
      <div class="container">
        <div class="navbar-header navbar-brand">
          <a href="https://github.com/tristanlatr/nltk">Natural Language Toolkit</a>
          <a href="index.html">API Documentation</a>
        </div>
      </div>
    </nav>

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="nltk.html">nltk</a></code>.<code><a href="nltk.tokenize.html">tokenize</a></code>.<code><a href="nltk.tokenize.punkt.html">punkt</a></code>.<code><a href="nltk.tokenize.punkt.PunktSentenceTokenizer.html">PunktSentenceTokenizer</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">PunktSentenceTokenizer</span>(<a href="nltk.tokenize.punkt.PunktBaseClass.html" title="nltk.tokenize.punkt.PunktBaseClass">PunktBaseClass</a>, <a href="nltk.tokenize.api.TokenizerI.html" title="nltk.tokenize.api.TokenizerI">TokenizerI</a>): <a href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1233">(source)</a></code></p>
        <p><a href="classIndex.html#nltk.tokenize.punkt.PunktSentenceTokenizer">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div><p class="pre">A sentence tokenizer which uses an unsupervised algorithm to build
a model for abbreviation words, collocations, and words that start
sentences; and then uses that model to find sentence boundaries.
This approach has been shown to work well for many European
languages.</p></div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1796">
  
  <tr class="method">
    
    <td>Method</td>
    <td><code><a href="#__init__">__init__</a></code></td>
    <td><span>train_text can either be the sole training text for this sentence boundary detector, or can be a PunktParameters object.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#train">train</a></code></td>
    <td><span>Derives parameters from a given training text, or uses the parameters given. Repeated calls to this method destroy previous parameters. For incremental training, instantiate a separate PunktTrainer instance.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#tokenize">tokenize</a></code></td>
    <td><span>Given a text, returns a list of the sentences in that text.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#debug_decisions">debug_decisions</a></code></td>
    <td><span>Classifies candidate periods as sentence breaks, yielding a dict for each that may be used to understand why the decision was made.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#span_tokenize">span_tokenize</a></code></td>
    <td><span>Given a text, generates (start, end) spans of sentences in the text.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#sentences_from_text">sentences_from_text</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#text_contains_sentbreak">text_contains_sentbreak</a></code></td>
    <td><span>Returns True if the given text includes a sentence break.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#sentences_from_text_legacy">sentences_from_text_legacy</a></code></td>
    <td><span>Given a text, generates the sentences in that text. Annotates all tokens, rather than just those with possible sentence breaks. Should produce the same results as ``sentences_from_text``.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#sentences_from_tokens">sentences_from_tokens</a></code></td>
    <td><span>Given a sequence of tokens, generates lists of tokens, each list corresponding to a sentence.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#dump">dump</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#PUNCTUATION">PUNCTUATION</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="#_params">_params</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_slices_from_text">_slices_from_text</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_realign_boundaries">_realign_boundaries</a></code></td>
    <td><span>Attempts to realign punctuation that falls after the period but should otherwise be included in the same sentence.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_annotate_tokens">_annotate_tokens</a></code></td>
    <td><span>Given a set of tokens augmented with markers for line-start and paragraph-start, returns an iterator through those tokens with full annotation including predicted sentence breaks.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_build_sentence_list">_build_sentence_list</a></code></td>
    <td><span>Given the original text and the list of augmented word tokens, construct and return a tokenized list of sentence strings.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_annotate_second_pass">_annotate_second_pass</a></code></td>
    <td><span>Performs a token-based classification (section 4) over the given tokens, making use of the orthographic heuristic (4.1.1), collocation heuristic (4.1.2) and frequent sentence starter heuristic (4.1.3).</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_second_pass_annotation">_second_pass_annotation</a></code></td>
    <td><span>Performs token-based classification over a pair of contiguous tokens updating the first.</span></td>
  </tr><tr class="method private">
    
    <td>Method</td>
    <td><code><a href="#_ortho_heuristic">_ortho_heuristic</a></code></td>
    <td><span>Decide whether the given token is the first token in a sentence.</span></td>
  </tr>
</table>
        
          <p class="inheritedFrom">
            Inherited from <code><a href="nltk.tokenize.punkt.PunktBaseClass.html">PunktBaseClass</a></code>:
          </p>
          <table class="children sortable" id="id1797">
  
  <tr class="baseinstancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_lang_vars">_lang_vars</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="baseinstancevariable private">
    
    <td>Instance Variable</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_Token">_Token</a></code></td>
    <td><span>The collection of parameters that determines the behavior of the punkt tokenizer.</span></td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_tokenize_words">_tokenize_words</a></code></td>
    <td><span class="undocumented">No summary</span></td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_annotate_first_pass">_annotate_first_pass</a></code></td>
    <td><span>Perform the first pass of annotation, which makes decisions based purely based on the word type of each word:</span></td>
  </tr><tr class="basemethod private">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_first_pass_annotation">_first_pass_annotation</a></code></td>
    <td><span>Performs type-based annotation on a single token.</span></td>
  </tr>
</table>
          
          <p class="inheritedFrom">
            Inherited from <code><a href="nltk.tokenize.api.TokenizerI.html">TokenizerI</a></code>:
          </p>
          <table class="children sortable" id="id1798">
  
  <tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#tokenize_sents">tokenize_sents</a></code></td>
    <td><span>Apply ``self.tokenize()`` to each element of ``strings``.  I.e.:</span></td>
  </tr><tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#span_tokenize_sents">span_tokenize_sents</a></code></td>
    <td><span>Apply ``self.span_tokenize()`` to each element of ``strings``.  I.e.:</span></td>
  </tr>
</table>
          

          
      </div>

      <div id="childList">

        <div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.__init__">
    
  </a>
  <a name="__init__">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">__init__</span>(self, train_text=None, verbose=False, lang_vars=None, token_cls=PunktToken):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1242">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.punkt.PunktBaseClass.html#__init__">nltk.tokenize.punkt.PunktBaseClass.__init__</a></code></div>
    
    <div><p class="pre">train_text can either be the sole training text for this sentence
boundary detector, or can be a PunktParameters object.</p></div>
  </div>
</div><div class="baseinstancevariable private">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._params">
    
  </a>
  <a name="_params">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_params</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1252">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.punkt.PunktBaseClass.html#_params">nltk.tokenize.punkt.PunktBaseClass._params</a></code></div>
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.train">
    
  </a>
  <a name="train">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">train</span>(self, train_text, verbose=False):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1254">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Derives parameters from a given training text, or uses the parameters
given. Repeated calls to this method destroy previous parameters. For
incremental training, instantiate a separate PunktTrainer instance.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.tokenize">
    
  </a>
  <a name="tokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">tokenize</span>(self, text, realign_boundaries=True):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1270">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.api.TokenizerI.html#tokenize">nltk.tokenize.api.TokenizerI.tokenize</a></code></div>
    
    <div><p class="pre">Given a text, returns a list of the sentences in that text.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.debug_decisions">
    
  </a>
  <a name="debug_decisions">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">debug_decisions</span>(self, text):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1276">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Classifies candidate periods as sentence breaks, yielding a dict for
each that may be used to understand why the decision was made.

See format_debug_decision() to help make this output readable.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.span_tokenize">
    
  </a>
  <a name="span_tokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">span_tokenize</span>(self, text, realign_boundaries=True):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1310">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.api.TokenizerI.html#span_tokenize">nltk.tokenize.api.TokenizerI.span_tokenize</a></code></div>
    
    <div><p class="pre">Given a text, generates (start, end) spans of sentences
in the text.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_text">
    
  </a>
  <a name="sentences_from_text">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">sentences_from_text</span>(self, text, realign_boundaries=True):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1321">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Given a text, generates the sentences in that text by only
testing candidate sentence breaks. If realign_boundaries is
True, includes in the sentence closing punctuation that
follows the period.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._slices_from_text">
    
  </a>
  <a name="_slices_from_text">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_slices_from_text</span>(self, text):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1330">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._realign_boundaries">
    
  </a>
  <a name="_realign_boundaries">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_realign_boundaries</span>(self, text, slices):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1345">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Attempts to realign punctuation that falls after the period but
should otherwise be included in the same sentence.

For example: "(Sent1.) Sent2." will otherwise be split as::

    ["(Sent1.", ") Sent1."].

This method will produce::

    ["(Sent1.)", "Sent2."].</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.text_contains_sentbreak">
    
  </a>
  <a name="text_contains_sentbreak">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">text_contains_sentbreak</span>(self, text):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1375">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Returns True if the given text includes a sentence break.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_text_legacy">
    
  </a>
  <a name="sentences_from_text_legacy">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">sentences_from_text_legacy</span>(self, text):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1387">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Given a text, generates the sentences in that text. Annotates all
tokens, rather than just those with possible sentence breaks. Should
produce the same results as ``sentences_from_text``.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_tokens">
    
  </a>
  <a name="sentences_from_tokens">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">sentences_from_tokens</span>(self, tokens):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1396">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Given a sequence of tokens, generates lists of tokens, each list
corresponding to a sentence.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._annotate_tokens">
    
  </a>
  <a name="_annotate_tokens">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_annotate_tokens</span>(self, tokens):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1411">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Given a set of tokens augmented with markers for line-start and
paragraph-start, returns an iterator through those tokens with full
annotation including predicted sentence breaks.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._build_sentence_list">
    
  </a>
  <a name="_build_sentence_list">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_build_sentence_list</span>(self, text, tokens):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1432">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Given the original text and the list of augmented word tokens,
construct and return a tokenized list of sentence strings.</p></div>
  </div>
</div><div class="basemethod">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.dump">
    
  </a>
  <a name="dump">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">dump</span>(self, tokens):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1487">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer.PUNCTUATION">
    
  </a>
  <a name="PUNCTUATION">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">PUNCTUATION</span> =
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1504">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._annotate_second_pass">
    
  </a>
  <a name="_annotate_second_pass">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_annotate_second_pass</span>(self, tokens):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1510">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Performs a token-based classification (section 4) over the given
tokens, making use of the orthographic heuristic (4.1.1), collocation
heuristic (4.1.2) and frequent sentence starter heuristic (4.1.3).</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._second_pass_annotation">
    
  </a>
  <a name="_second_pass_annotation">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_second_pass_annotation</span>(self, aug_tok1, aug_tok2):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1520">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Performs token-based classification over a pair of contiguous tokens
updating the first.</p></div>
  </div>
</div><div class="basemethod private">
  
  <a name="nltk.tokenize.punkt.PunktSentenceTokenizer._ortho_heuristic">
    
  </a>
  <a name="_ortho_heuristic">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_ortho_heuristic</span>(self, aug_tok):
    <a class="functionSourceLink" href="https://github.com/tristanlatr/nltk/tree/cab27f08bc0f78151e7dd16ec110d324f8c05a72/nltk/tokenize/punkt.py#L1603">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Decide whether the given token is the first token in a sentence.</p></div>
  </div>
</div>

      </div>
      <address>
        <a href="index.html">API Documentation</a> for <a href="https://github.com/tristanlatr/nltk">Natural Language Toolkit</a>, generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a> 21.2.2 at 2021-06-22 02:47:44.
      </address>

    </div>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>