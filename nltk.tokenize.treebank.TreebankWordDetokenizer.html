<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>nltk.tokenize.treebank.TreebankWordDetokenizer</title>
    <meta name="generator" content="pydoctor 21.2.2"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
          <span class="navbar-brand">
            <a href="https://github.com/tristanlatr/nltk" class="projecthome">Natural Language Toolkit</a> <a href="index.html">API Documentation</a>
          </span>

          <a href="moduleIndex.html">
            Modules
          </a>

          <a href="classIndex.html">
            Classes
          </a>

          <a href="nameIndex.html">
            Names
          </a>
      </div>

    </div>
  </div>
</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="nltk.html">nltk</a></code><wbr></wbr>.<code><a href="nltk.tokenize.html">tokenize</a></code><wbr></wbr>.<code><a href="nltk.tokenize.treebank.html">treebank</a></code><wbr></wbr>.<code><a href="nltk.tokenize.treebank.TreebankWordDetokenizer.html">TreebankWordDetokenizer</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">TreebankWordDetokenizer</span>(<a href="nltk.tokenize.api.TokenizerI.html" title="nltk.tokenize.api.TokenizerI">TokenizerI</a>): <a href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L193" class="sourceLink">(source)</a></code></p>
        <p><a href="classIndex.html#nltk.tokenize.treebank.TreebankWordDetokenizer">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div><p class="pre">The Treebank detokenizer uses the reverse regex operations corresponding to
the Treebank tokenizer's regexes.

Note:
- There're additional assumption mades when undoing the padding of [;@#$%&amp;]
  punctuation symbols that isn't presupposed in the TreebankTokenizer.
- There're additional regexes added in reversing the parentheses tokenization,
   - the r'([\]\)\}\&gt;])\s([:;,.])' removes the additional right padding added
     to the closing parentheses precedding [:;,.].
- It's not possible to return the original whitespaces as they were because
  there wasn't explicit records of where '\n', '\t' or '\s' were removed at
  the text.split() operation.

    &gt;&gt;&gt; from nltk.tokenize.treebank import TreebankWordTokenizer, TreebankWordDetokenizer
    &gt;&gt;&gt; s = '''Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.\nThanks.'''
    &gt;&gt;&gt; d = TreebankWordDetokenizer()
    &gt;&gt;&gt; t = TreebankWordTokenizer()
    &gt;&gt;&gt; toks = t.tokenize(s)
    &gt;&gt;&gt; d.detokenize(toks)
    'Good muffins cost $3.88 in New York. Please buy me two of them. Thanks.'

The MXPOST parentheses substitution can be undone using the `convert_parentheses`
parameter:

&gt;&gt;&gt; s = '''Good muffins cost $3.88\nin New (York).  Please (buy) me\ntwo of them.\n(Thanks).'''
&gt;&gt;&gt; expected_tokens = ['Good', 'muffins', 'cost', '$', '3.88', 'in',
... 'New', '-LRB-', 'York', '-RRB-', '.', 'Please', '-LRB-', 'buy',
... '-RRB-', 'me', 'two', 'of', 'them.', '-LRB-', 'Thanks', '-RRB-', '.']
&gt;&gt;&gt; expected_tokens == t.tokenize(s, convert_parentheses=True)
True
&gt;&gt;&gt; expected_detoken = 'Good muffins cost $3.88 in New (York). Please (buy) me two of them. (Thanks).'
&gt;&gt;&gt; expected_detoken == d.detokenize(t.tokenize(s, convert_parentheses=True), convert_parentheses=True)
True

During tokenization it's safe to add more spaces but during detokenization,
simply undoing the padding doesn't really help.

- During tokenization, left and right pad is added to [!?], when
  detokenizing, only left shift the [!?] is needed.
  Thus (re.compile(r'\s([?!])'), r'\g&lt;1&gt;')

- During tokenization [:,] are left and right padded but when detokenizing,
  only left shift is necessary and we keep right pad after comma/colon
  if the string after is a non-digit.
  Thus (re.compile(r'\s([:,])\s([^\d])'), r'\1 \2')

&gt;&gt;&gt; from nltk.tokenize.treebank import TreebankWordDetokenizer
&gt;&gt;&gt; toks = ['hello', ',', 'i', 'ca', "n't", 'feel', 'my', 'feet', '!', 'Help', '!', '!']
&gt;&gt;&gt; twd = TreebankWordDetokenizer()
&gt;&gt;&gt; twd.detokenize(toks)
"hello, i can't feel my feet! Help!!"

&gt;&gt;&gt; toks = ['hello', ',', 'i', "can't", 'feel', ';', 'my', 'feet', '!',
... 'Help', '!', '!', 'He', 'said', ':', 'Help', ',', 'help', '?', '!']
&gt;&gt;&gt; twd.detokenize(toks)
"hello, i can't feel; my feet! Help!! He said: Help, help?!"</p></div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1853">
  
  
  <tr class="method">
    
    <td>Method</td>
    <td><code><a href="#detokenize">detokenize</a></code></td>
    <td><span>Duck-typing the abstract *tokenize()*.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#tokenize">tokenize</a></code></td>
    <td><span>Treebank detokenizer, created by undoing the regexes from the TreebankWordTokenizer.tokenize.</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#CONTRACTIONS2">CONTRACTIONS2</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#CONTRACTIONS3">CONTRACTIONS3</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#CONVERT_PARENTHESES">CONVERT_PARENTHESES</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#DOUBLE_DASHES">DOUBLE_DASHES</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#ENDING_QUOTES">ENDING_QUOTES</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#PARENS_BRACKETS">PARENS_BRACKETS</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#PUNCTUATION">PUNCTUATION</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#STARTING_QUOTES">STARTING_QUOTES</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable private">
    
    <td>Class Variable</td>
    <td><code><a href="#_contractions">_contractions</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr>
</table>
        
          <p class="inheritedFrom">
            Inherited from <code><a href="nltk.tokenize.api.TokenizerI.html">TokenizerI</a></code>:
          </p>
          <table class="children sortable" id="id1854">
  
  
  <tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#span_tokenize">span_tokenize</a></code></td>
    <td><span>Identify the tokens using integer offsets ``(start_i, end_i)``, where ``s[start_i:end_i]`` is the corresponding token.</span></td>
  </tr><tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#span_tokenize_sents">span_tokenize_sents</a></code></td>
    <td><span>Apply ``self.span_tokenize()`` to each element of ``strings``.  I.e.:</span></td>
  </tr><tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#tokenize_sents">tokenize_sents</a></code></td>
    <td><span>Apply ``self.tokenize()`` to each element of ``strings``.  I.e.:</span></td>
  </tr>
</table>
          

          
      </div>

      <div id="childList">

        <div class="basemethod">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.detokenize">
    
  </a>
  <a name="detokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">detokenize</span>(self, tokens, convert_parentheses=False):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L369">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="pre">Duck-typing the abstract *tokenize()*.</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.tokenize">
    
  </a>
  <a name="tokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">tokenize</span>(self, tokens, convert_parentheses=False):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L323">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.api.TokenizerI.html#tokenize">nltk.tokenize.api.TokenizerI.tokenize</a></code></div>
    
    <div><p class="pre">Treebank detokenizer, created by undoing the regexes from
the TreebankWordTokenizer.tokenize.

:param tokens: A list of strings, i.e. tokenized text.
:type tokens: list(str)
:return: str</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.CONTRACTIONS2">
    
  </a>
  <a name="CONTRACTIONS2">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">CONTRACTIONS2</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L254">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.CONTRACTIONS3">
    
  </a>
  <a name="CONTRACTIONS3">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">CONTRACTIONS3</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L258">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.CONVERT_PARENTHESES">
    
  </a>
  <a name="CONVERT_PARENTHESES">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">CONVERT_PARENTHESES</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L279">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.DOUBLE_DASHES">
    
  </a>
  <a name="DOUBLE_DASHES">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">DOUBLE_DASHES</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L276">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.ENDING_QUOTES">
    
  </a>
  <a name="ENDING_QUOTES">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">ENDING_QUOTES</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L264">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.PARENS_BRACKETS">
    
  </a>
  <a name="PARENS_BRACKETS">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">PARENS_BRACKETS</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L289">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.PUNCTUATION">
    
  </a>
  <a name="PUNCTUATION">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">PUNCTUATION</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L296">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.STARTING_QUOTES">
    
  </a>
  <a name="STARTING_QUOTES">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">STARTING_QUOTES</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L317">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable private">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer._contractions">
    
  </a>
  <a name="_contractions">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_contractions</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/f83d0acf07ed0fd627306ec5ae73265b05025e51/nltk/tokenize/treebank.py#L253">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div>

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for <a href="https://github.com/tristanlatr/nltk" class="projecthome">Natural Language Toolkit</a>,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    21.2.2 at 2021-06-22 02:51:08.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>