<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>nltk.tokenize.treebank.TreebankWordDetokenizer</title>
    <meta name="generator" content="pydoctor 21.2.2"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
          <span class="navbar-brand">
            <a href="https://github.com/tristanlatr/nltk" class="projecthome">Natural Language Toolkit</a> <a href="index.html">API Documentation</a>
          </span>

          <a href="moduleIndex.html">
            Modules
          </a>

          <a href="classIndex.html">
            Classes
          </a>

          <a href="nameIndex.html">
            Names
          </a>
      </div>

    </div>
  </div>
</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="nltk.html">nltk</a></code><wbr></wbr>.<code><a href="nltk.tokenize.html">tokenize</a></code><wbr></wbr>.<code><a href="nltk.tokenize.treebank.html">treebank</a></code><wbr></wbr>.<code><a href="nltk.tokenize.treebank.TreebankWordDetokenizer.html">TreebankWordDetokenizer</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">TreebankWordDetokenizer</span>(<a href="nltk.tokenize.api.TokenizerI.html" title="nltk.tokenize.api.TokenizerI">TokenizerI</a>): <a href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L193" class="sourceLink">(source)</a></code></p>
        <p><a href="classIndex.html#nltk.tokenize.treebank.TreebankWordDetokenizer">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div><p>The Treebank detokenizer uses the reverse regex operations corresponding to
the Treebank tokenizer's regexes.</p>
<p>Note:
- There're additional assumption mades when undoing the padding of [;@#$%&amp;]</p>
<blockquote>
punctuation symbols that isn't presupposed in the TreebankTokenizer.</blockquote>
<ul>
<li><dl class="rst-first rst-docutils">
<dt>There're additional regexes added in reversing the parentheses tokenization,</dt>
<dd><ul class="rst-first rst-last rst-simple">
<li>the r'([])}&gt;])s([:;,.])' removes the additional right padding added
to the closing parentheses precedding [:;,.].</li>
</ul>
</dd>
</dl>
</li>
<li><p class="rst-first">It's not possible to return the original whitespaces as they were because
there wasn't explicit records of where 'n', 't' or 's' were removed at
the text.split() operation.</p>
<blockquote>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> nltk.tokenize.treebank <span class="py-keyword">import</span> TreebankWordTokenizer, TreebankWordDetokenizer
<span class="py-prompt">&gt;&gt;&gt; </span>s = <span class="py-string">'''Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.\nThanks.'''</span>
<span class="py-prompt">&gt;&gt;&gt; </span>d = TreebankWordDetokenizer()
<span class="py-prompt">&gt;&gt;&gt; </span>t = TreebankWordTokenizer()
<span class="py-prompt">&gt;&gt;&gt; </span>toks = t.tokenize(s)
<span class="py-prompt">&gt;&gt;&gt; </span>d.detokenize(toks)
<span class="py-output">'Good muffins cost $3.88 in New York. Please buy me two of them. Thanks.'</span>
</pre></blockquote>
</li>
</ul>
<p>The MXPOST parentheses substitution can be undone using the <code>convert_parentheses</code>
parameter:</p>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span>s = <span class="py-string">'''Good muffins cost $3.88\nin New (York).  Please (buy) me\ntwo of them.\n(Thanks).'''</span>
<span class="py-prompt">&gt;&gt;&gt; </span>expected_tokens = [<span class="py-string">'Good'</span>, <span class="py-string">'muffins'</span>, <span class="py-string">'cost'</span>, <span class="py-string">'$'</span>, <span class="py-string">'3.88'</span>, <span class="py-string">'in'</span>,
<span class="py-more">... </span><span class="py-string">'New'</span>, <span class="py-string">'-LRB-'</span>, <span class="py-string">'York'</span>, <span class="py-string">'-RRB-'</span>, <span class="py-string">'.'</span>, <span class="py-string">'Please'</span>, <span class="py-string">'-LRB-'</span>, <span class="py-string">'buy'</span>,
<span class="py-more">... </span><span class="py-string">'-RRB-'</span>, <span class="py-string">'me'</span>, <span class="py-string">'two'</span>, <span class="py-string">'of'</span>, <span class="py-string">'them.'</span>, <span class="py-string">'-LRB-'</span>, <span class="py-string">'Thanks'</span>, <span class="py-string">'-RRB-'</span>, <span class="py-string">'.'</span>]
<span class="py-prompt">&gt;&gt;&gt; </span>expected_tokens == t.tokenize(s, convert_parentheses=<span class="py-builtin">True</span>)
<span class="py-output">True</span>
<span class="py-prompt">&gt;&gt;&gt; </span>expected_detoken = <span class="py-string">'Good muffins cost $3.88 in New (York). Please (buy) me two of them. (Thanks).'</span>
<span class="py-prompt">&gt;&gt;&gt; </span>expected_detoken == d.detokenize(t.tokenize(s, convert_parentheses=<span class="py-builtin">True</span>), convert_parentheses=<span class="py-builtin">True</span>)
<span class="py-output">True</span>
</pre><p>During tokenization it's safe to add more spaces but during detokenization,
simply undoing the padding doesn't really help.</p>
<ul class="rst-simple">
<li>During tokenization, left and right pad is added to [!?], when
detokenizing, only left shift the [!?] is needed.
Thus (re.compile(r's([?!])'), r'g&lt;1&gt;')</li>
<li>During tokenization [:,] are left and right padded but when detokenizing,
only left shift is necessary and we keep right pad after comma/colon
if the string after is a non-digit.
Thus (re.compile(r's([:,])s([^d])'), r'1 2')</li>
</ul>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">from</span> nltk.tokenize.treebank <span class="py-keyword">import</span> TreebankWordDetokenizer
<span class="py-prompt">&gt;&gt;&gt; </span>toks = [<span class="py-string">'hello'</span>, <span class="py-string">','</span>, <span class="py-string">'i'</span>, <span class="py-string">'ca'</span>, <span class="py-string">"n't"</span>, <span class="py-string">'feel'</span>, <span class="py-string">'my'</span>, <span class="py-string">'feet'</span>, <span class="py-string">'!'</span>, <span class="py-string">'Help'</span>, <span class="py-string">'!'</span>, <span class="py-string">'!'</span>]
<span class="py-prompt">&gt;&gt;&gt; </span>twd = TreebankWordDetokenizer()
<span class="py-prompt">&gt;&gt;&gt; </span>twd.detokenize(toks)
<span class="py-output">"hello, i can't feel my feet! Help!!"</span>
</pre><pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span>toks = [<span class="py-string">'hello'</span>, <span class="py-string">','</span>, <span class="py-string">'i'</span>, <span class="py-string">"can't"</span>, <span class="py-string">'feel'</span>, <span class="py-string">';'</span>, <span class="py-string">'my'</span>, <span class="py-string">'feet'</span>, <span class="py-string">'!'</span>,
<span class="py-more">... </span><span class="py-string">'Help'</span>, <span class="py-string">'!'</span>, <span class="py-string">'!'</span>, <span class="py-string">'He'</span>, <span class="py-string">'said'</span>, <span class="py-string">':'</span>, <span class="py-string">'Help'</span>, <span class="py-string">','</span>, <span class="py-string">'help'</span>, <span class="py-string">'?'</span>, <span class="py-string">'!'</span>]
<span class="py-prompt">&gt;&gt;&gt; </span>twd.detokenize(toks)
<span class="py-output">"hello, i can't feel; my feet! Help!! He said: Help, help?!"</span>
</pre></div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1857">
  
  
  <tr class="method">
    
    <td>Method</td>
    <td><code><a href="#detokenize">detokenize</a></code></td>
    <td><span>Duck-typing the abstract <em>tokenize()</em>.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#tokenize">tokenize</a></code></td>
    <td><span>Treebank detokenizer, created by undoing the regexes from the TreebankWordTokenizer.tokenize.</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#CONTRACTIONS2">CONTRACTIONS2</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#CONTRACTIONS3">CONTRACTIONS3</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#CONVERT_PARENTHESES">CONVERT_PARENTHESES</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#DOUBLE_DASHES">DOUBLE_DASHES</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#ENDING_QUOTES">ENDING_QUOTES</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#PARENS_BRACKETS">PARENS_BRACKETS</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#PUNCTUATION">PUNCTUATION</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable">
    
    <td>Class Variable</td>
    <td><code><a href="#STARTING_QUOTES">STARTING_QUOTES</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="classvariable private">
    
    <td>Class Variable</td>
    <td><code><a href="#_contractions">_contractions</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr>
</table>
        
          <p class="inheritedFrom">
            Inherited from <code><a href="nltk.tokenize.api.TokenizerI.html">TokenizerI</a></code>:
          </p>
          <table class="children sortable" id="id1858">
  
  
  <tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#span_tokenize">span_tokenize</a></code></td>
    <td><span>Identify the tokens using integer offsets <tt class="rst-docutils literal">(start_i, end_i)</tt>, where <tt class="rst-docutils literal">s[start_i:end_i]</tt> is the corresponding token.</span></td>
  </tr><tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#span_tokenize_sents">span_tokenize_sents</a></code></td>
    <td><span>Apply <tt class="rst-docutils literal">self.span_tokenize()</tt> to each element of <tt class="rst-docutils literal">strings</tt>.  I.e.:</span></td>
  </tr><tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#tokenize_sents">tokenize_sents</a></code></td>
    <td><span>Apply <tt class="rst-docutils literal">self.tokenize()</tt> to each element of <tt class="rst-docutils literal">strings</tt>.  I.e.:</span></td>
  </tr>
</table>
          

          
      </div>

      <div id="childList">

        <div class="basemethod">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.detokenize">
    
  </a>
  <a name="detokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">detokenize</span>(self, tokens, convert_parentheses=False):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L369">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Duck-typing the abstract <em>tokenize()</em>.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.tokenize">
    
  </a>
  <a name="tokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">tokenize</span>(self, tokens, convert_parentheses=False):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L323">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.api.TokenizerI.html#tokenize">nltk.tokenize.api.TokenizerI.tokenize</a></code></div>
    
    <div>Treebank detokenizer, created by undoing the regexes from
the TreebankWordTokenizer.tokenize.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">tokens:</span>list(str)</td><td class="fieldArgDesc">A list of strings, i.e. tokenized text.</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">convert_parentheses</span></td><td class="fieldArgDesc"><span class="undocumented">Undocumented</span></td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td colspan="2">str</td></tr></table></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.CONTRACTIONS2">
    
  </a>
  <a name="CONTRACTIONS2">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">CONTRACTIONS2</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L254">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.CONTRACTIONS3">
    
  </a>
  <a name="CONTRACTIONS3">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">CONTRACTIONS3</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L258">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.CONVERT_PARENTHESES">
    
  </a>
  <a name="CONVERT_PARENTHESES">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">CONVERT_PARENTHESES</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L279">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.DOUBLE_DASHES">
    
  </a>
  <a name="DOUBLE_DASHES">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">DOUBLE_DASHES</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L276">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.ENDING_QUOTES">
    
  </a>
  <a name="ENDING_QUOTES">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">ENDING_QUOTES</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L264">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.PARENS_BRACKETS">
    
  </a>
  <a name="PARENS_BRACKETS">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">PARENS_BRACKETS</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L289">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.PUNCTUATION">
    
  </a>
  <a name="PUNCTUATION">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">PUNCTUATION</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L296">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer.STARTING_QUOTES">
    
  </a>
  <a name="STARTING_QUOTES">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">STARTING_QUOTES</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L317">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseclassvariable private">
  
  
  <a name="nltk.tokenize.treebank.TreebankWordDetokenizer._contractions">
    
  </a>
  <a name="_contractions">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">_contractions</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/treebank.py#L253">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div>

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for <a href="https://github.com/tristanlatr/nltk" class="projecthome">Natural Language Toolkit</a>,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    21.2.2 at 2021-06-22 02:56:13.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>