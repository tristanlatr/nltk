<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>nltk.tokenize.repp.ReppTokenizer</title>
    <meta name="generator" content="pydoctor 21.2.2"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
          <span class="navbar-brand">
            <a href="https://github.com/tristanlatr/nltk" class="projecthome">Natural Language Toolkit</a> <a href="index.html">API Documentation</a>
          </span>

          <a href="moduleIndex.html">
            Modules
          </a>

          <a href="classIndex.html">
            Classes
          </a>

          <a href="nameIndex.html">
            Names
          </a>
      </div>

    </div>
  </div>
</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="nltk.html">nltk</a></code><wbr></wbr>.<code><a href="nltk.tokenize.html">tokenize</a></code><wbr></wbr>.<code><a href="nltk.tokenize.repp.html">repp</a></code><wbr></wbr>.<code><a href="nltk.tokenize.repp.ReppTokenizer.html">ReppTokenizer</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">ReppTokenizer</span>(<a href="nltk.tokenize.api.TokenizerI.html" title="nltk.tokenize.api.TokenizerI">TokenizerI</a>): <a href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L23" class="sourceLink">(source)</a></code></p>
        <p><a href="classIndex.html#nltk.tokenize.repp.ReppTokenizer">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div><p>A class for word tokenization using the REPP parser described in
Rebecca Dridan and Stephan Oepen (2012) Tokenization: Returning to a
Long Solved Problem - A Survey, Contrastive  Experiment, Recommendations,
and Toolkit. In ACL. <a class="rst-reference external" href="http://anthology.aclweb.org/P/P12/P12-2.pdf#page=406" target="_top">http://anthology.aclweb.org/P/P12/P12-2.pdf#page=406</a></p>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span>sents = [<span class="py-string">'Tokenization is widely regarded as a solved problem due to the high accuracy that rulebased tokenizers achieve.'</span> ,
<span class="py-more">... </span><span class="py-string">'But rule-based tokenizers are hard to maintain and their rules language specific.'</span> ,
<span class="py-more">... </span><span class="py-string">'We evaluated our method on three languages and obtained error rates of 0.27% (English), 0.35% (Dutch) and 0.76% (Italian) for our best models.'</span>
<span class="py-more">... </span>]
<span class="py-prompt">&gt;&gt;&gt; </span>tokenizer = ReppTokenizer(<span class="py-string">'/home/alvas/repp/'</span>) <span class="py-comment"># doctest: +SKIP</span>
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">for</span> sent <span class="py-keyword">in</span> sents:                             <span class="py-comment"># doctest: +SKIP</span>
<span class="py-more">... </span>    tokenizer.tokenize(sent)                   <span class="py-comment"># doctest: +SKIP</span>
<span class="py-more">...</span>
<span class="py-output">(u'Tokenization', u'is', u'widely', u'regarded', u'as', u'a', u'solved', u'problem', u'due', u'to', u'the', u'high', u'accuracy', u'that', u'rulebased', u'tokenizers', u'achieve', u'.')</span>
<span class="py-output">(u'But', u'rule-based', u'tokenizers', u'are', u'hard', u'to', u'maintain', u'and', u'their', u'rules', u'language', u'specific', u'.')</span>
<span class="py-output">(u'We', u'evaluated', u'our', u'method', u'on', u'three', u'languages', u'and', u'obtained', u'error', u'rates', u'of', u'0.27', u'%', u'(', u'English', u')', u',', u'0.35', u'%', u'(', u'Dutch', u')', u'and', u'0.76', u'%', u'(', u'Italian', u')', u'for', u'our', u'best', u'models', u'.')</span>
</pre><pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">for</span> sent <span class="py-keyword">in</span> tokenizer.tokenize_sents(sents): <span class="py-comment"># doctest: +SKIP</span>
<span class="py-more">... </span>    <span class="py-builtin">print</span>(sent)                              <span class="py-comment"># doctest: +SKIP</span>
<span class="py-more">...</span>
<span class="py-output">(u'Tokenization', u'is', u'widely', u'regarded', u'as', u'a', u'solved', u'problem', u'due', u'to', u'the', u'high', u'accuracy', u'that', u'rulebased', u'tokenizers', u'achieve', u'.')</span>
<span class="py-output">(u'But', u'rule-based', u'tokenizers', u'are', u'hard', u'to', u'maintain', u'and', u'their', u'rules', u'language', u'specific', u'.')</span>
<span class="py-output">(u'We', u'evaluated', u'our', u'method', u'on', u'three', u'languages', u'and', u'obtained', u'error', u'rates', u'of', u'0.27', u'%', u'(', u'English', u')', u',', u'0.35', u'%', u'(', u'Dutch', u')', u'and', u'0.76', u'%', u'(', u'Italian', u')', u'for', u'our', u'best', u'models', u'.')</span>
<span class="py-prompt">&gt;&gt;&gt; </span><span class="py-keyword">for</span> sent <span class="py-keyword">in</span> tokenizer.tokenize_sents(sents, keep_token_positions=<span class="py-builtin">True</span>): <span class="py-comment"># doctest: +SKIP</span>
<span class="py-more">... </span>    <span class="py-builtin">print</span>(sent)                                                         <span class="py-comment"># doctest: +SKIP</span>
<span class="py-more">...</span>
<span class="py-output">[(u'Tokenization', 0, 12), (u'is', 13, 15), (u'widely', 16, 22), (u'regarded', 23, 31), (u'as', 32, 34), (u'a', 35, 36), (u'solved', 37, 43), (u'problem', 44, 51), (u'due', 52, 55), (u'to', 56, 58), (u'the', 59, 62), (u'high', 63, 67), (u'accuracy', 68, 76), (u'that', 77, 81), (u'rulebased', 82, 91), (u'tokenizers', 92, 102), (u'achieve', 103, 110), (u'.', 110, 111)]</span>
<span class="py-output">[(u'But', 0, 3), (u'rule-based', 4, 14), (u'tokenizers', 15, 25), (u'are', 26, 29), (u'hard', 30, 34), (u'to', 35, 37), (u'maintain', 38, 46), (u'and', 47, 50), (u'their', 51, 56), (u'rules', 57, 62), (u'language', 63, 71), (u'specific', 72, 80), (u'.', 80, 81)]</span>
<span class="py-output">[(u'We', 0, 2), (u'evaluated', 3, 12), (u'our', 13, 16), (u'method', 17, 23), (u'on', 24, 26), (u'three', 27, 32), (u'languages', 33, 42), (u'and', 43, 46), (u'obtained', 47, 55), (u'error', 56, 61), (u'rates', 62, 67), (u'of', 68, 70), (u'0.27', 71, 75), (u'%', 75, 76), (u'(', 77, 78), (u'English', 78, 85), (u')', 85, 86), (u',', 86, 87), (u'0.35', 88, 92), (u'%', 92, 93), (u'(', 94, 95), (u'Dutch', 95, 100), (u')', 100, 101), (u'and', 102, 105), (u'0.76', 106, 110), (u'%', 110, 111), (u'(', 112, 113), (u'Italian', 113, 120), (u')', 120, 121), (u'for', 122, 125), (u'our', 126, 129), (u'best', 130, 134), (u'models', 135, 141), (u'.', 141, 142)]</span>
</pre></div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id1820">
  
  
  <tr class="staticmethod">
    
    <td>Static Method</td>
    <td><code><a href="#parse_repp_outputs">parse_repp_outputs</a></code></td>
    <td><span>This module parses the tri-tuple format that REPP outputs using the "--format triple" option and returns an generator with tuple of string tokens.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#__init__">__init__</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#find_repptokenizer">find_repptokenizer</a></code></td>
    <td><span>A module to find REPP tokenizer binary and its <em>repp.set</em> config file.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#generate_repp_command">generate_repp_command</a></code></td>
    <td><span>This module generates the REPP command to be used at the terminal.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#tokenize">tokenize</a></code></td>
    <td><span>Use Repp to tokenize a single sentence.</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#tokenize_sents">tokenize_sents</a></code></td>
    <td><span>Tokenize multiple sentences using Repp.</span></td>
  </tr><tr class="instancevariable">
    
    <td>Instance Variable</td>
    <td><code><a href="#encoding">encoding</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable">
    
    <td>Instance Variable</td>
    <td><code><a href="#repp_dir">repp_dir</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable">
    
    <td>Instance Variable</td>
    <td><code><a href="#working_dir">working_dir</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="staticmethod private">
    
    <td>Static Method</td>
    <td><code><a href="#_execute">_execute</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr>
</table>
        
          <p class="inheritedFrom">
            Inherited from <code><a href="nltk.tokenize.api.TokenizerI.html">TokenizerI</a></code>:
          </p>
          <table class="children sortable" id="id1821">
  
  
  <tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#span_tokenize">span_tokenize</a></code></td>
    <td><span>Identify the tokens using integer offsets <tt class="rst-docutils literal">(start_i, end_i)</tt>, where <tt class="rst-docutils literal">s[start_i:end_i]</tt> is the corresponding token.</span></td>
  </tr><tr class="basemethod">
    
    <td>Method</td>
    <td><code><a href="nltk.tokenize.api.TokenizerI.html#span_tokenize_sents">span_tokenize_sents</a></code></td>
    <td><span>Apply <tt class="rst-docutils literal">self.span_tokenize()</tt> to each element of <tt class="rst-docutils literal">strings</tt>.  I.e.:</span></td>
  </tr>
</table>
          

          
      </div>

      <div id="childList">

        <div class="basestaticmethod">
  
  
  <a name="nltk.tokenize.repp.ReppTokenizer.parse_repp_outputs">
    
  </a>
  <a name="parse_repp_outputs">
    
  </a>
  <div class="functionHeader">
    @staticmethod<br />
    <span class="py-keyword">def</span> <span class="py-defname">parse_repp_outputs</span>(repp_output):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L119">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>This module parses the tri-tuple format that REPP outputs using the
"--format triple" option and returns an generator with tuple of string
tokens.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">repp_output:</span>type</td><td class="fieldArgDesc"></td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">iter(tuple)</td><td class="fieldArgDesc">an iterable of the tokenized sentences as tuples of strings</td></tr></table></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.repp.ReppTokenizer.__init__">
    
  </a>
  <a name="__init__">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">__init__</span>(self, repp_dir, encoding='utf8'):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L56">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.repp.ReppTokenizer.find_repptokenizer">
    
  </a>
  <a name="find_repptokenizer">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">find_repptokenizer</span>(self, repp_dirname):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L140">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>A module to find REPP tokenizer binary and its <em>repp.set</em> config file.</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.repp.ReppTokenizer.generate_repp_command">
    
  </a>
  <a name="generate_repp_command">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">generate_repp_command</span>(self, inputfilename):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L100">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>This module generates the REPP command to be used at the terminal.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">inputfilename:</span>str</td><td class="fieldArgDesc">path to the input file</td></tr></table></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.repp.ReppTokenizer.tokenize">
    
  </a>
  <a name="tokenize">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">tokenize</span>(self, sentence):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L63">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.api.TokenizerI.html#tokenize">nltk.tokenize.api.TokenizerI.tokenize</a></code></div>
    
    <div>Use Repp to tokenize a single sentence.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">sentence:</span>str</td><td class="fieldArgDesc">A single sentence string.</td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">tuple(str)</td><td class="fieldArgDesc">A tuple of tokens.</td></tr></table></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="nltk.tokenize.repp.ReppTokenizer.tokenize_sents">
    
  </a>
  <a name="tokenize_sents">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">tokenize_sents</span>(self, sentences, keep_token_positions=False):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L74">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="nltk.tokenize.api.TokenizerI.html#tokenize_sents">nltk.tokenize.api.TokenizerI.tokenize_sents</a></code></div>
    
    <div>Tokenize multiple sentences using Repp.<table class="fieldTable"><tr class="fieldStart"><td class="fieldName" colspan="2">Parameters</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">sentences:</span>list(str)</td><td class="fieldArgDesc">A list of sentence strings.</td></tr><tr><td class="fieldArgContainer"><span class="fieldArg">keep_token_positions</span></td><td class="fieldArgDesc"><span class="undocumented">Undocumented</span></td></tr><tr class="fieldStart"><td class="fieldName" colspan="2">Returns</td></tr><tr><td class="fieldArgContainer">iter(tuple(str))</td><td class="fieldArgDesc">A list of tuples of tokens</td></tr></table></div>
  </div>
</div><div class="baseinstancevariable">
  
  
  <a name="nltk.tokenize.repp.ReppTokenizer.encoding">
    
  </a>
  <a name="encoding">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">encoding</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L61">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable">
  
  
  <a name="nltk.tokenize.repp.ReppTokenizer.repp_dir">
    
  </a>
  <a name="repp_dir">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">repp_dir</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L57">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="baseinstancevariable">
  
  
  <a name="nltk.tokenize.repp.ReppTokenizer.working_dir">
    
  </a>
  <a name="working_dir">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">working_dir</span> =
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L59">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basestaticmethod private">
  
  
  <a name="nltk.tokenize.repp.ReppTokenizer._execute">
    
  </a>
  <a name="_execute">
    
  </a>
  <div class="functionHeader">
    @staticmethod<br />
    <span class="py-keyword">def</span> <span class="py-defname">_execute</span>(cmd):
    <a class="sourceLink" href="https://github.com/tristanlatr/nltk/tree/03a34b1932460e632ce9048adc0ccabbc7c0558c/nltk/tokenize/repp.py#L113">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div>

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for <a href="https://github.com/tristanlatr/nltk" class="projecthome">Natural Language Toolkit</a>,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    21.2.2 at 2021-06-22 02:56:13.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>